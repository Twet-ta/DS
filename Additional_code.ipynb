{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predproc.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN2+u2dClkDOgIioIkD87y2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Twet-ta/DS/blob/main/Additional_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Вспомогательный код\n",
        "---"
      ],
      "metadata": {
        "id": "56sw1M2lFFrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Код к первому эксперименту"
      ],
      "metadata": {
        "id": "nwZ8Rk89eSYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transf, y_train = transform_data(\n",
        "    transf=BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME),\n",
        "    data_loader=train_data_loader,\n",
        "    device=device,\n",
        "    n_hidden_layer=[1, 2, 3], #номер скрытого слоя для извлечения представления, если не указан, то берется выход для CLF\n",
        ")"
      ],
      "metadata": {
        "id": "OXRP1nEiM5lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transf, y_test = transform_data(\n",
        "    transf=BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME),\n",
        "    data_loader=test_data_loader,\n",
        "    device=device,\n",
        "    n_hidden_layer=[1, 2, 3], #номер скрытого слоя для извлечения представления, если не указан, то берется выход для CLF\n",
        ")"
      ],
      "metadata": {
        "id": "FR1vRPylM5lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "par = [[-1], [-2], np.arange(1, 2), np.arange(1, 6), np.arange(1, 11), np.arange(1, MAX_LEN)] #способы перебора\n",
        "accuracy = []\n",
        "for p in par:\n",
        "    clf = LogisticRegression(max_iter=1000)\n",
        "    print(sum(cross_val_score(clf, img_of_txt(train_transf, var=p), y_train, cv=3))/3)\n",
        "    clf.fit(img_of_txt(train_transf, var=p), y_train)\n",
        "    accuracy.append(accuracy_score(y_test, clf.predict(img_of_txt(test_transf, var=p))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bSIHj-kjRsH",
        "outputId": "3a092fcd-6bc4-4bee-e9af-e8d9ee50b56c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8098472754245093\n",
            "0.5036344108682563\n",
            "0.7678767929850981\n",
            "0.7415011974534141\n",
            "0.7634228483972691\n",
            "0.8245008054756182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFR-tu4ikCdZ",
        "outputId": "89f7a9f1-625e-4cff-ad7c-3de484d997b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8170731707317073, 0.49437148217636023, 0.7861163227016885, 0.7429643527204502, 0.7560975609756098, 0.8086303939962477]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Код для подсчета accuracy для разных трансформеров (3 эксперимент)"
      ],
      "metadata": {
        "id": "y0sCei2JKUAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-large-cased'\n",
        "train_data_loader, test_data_loader, tokenizer = create_new_transf(train, test, tokenizer, MAX_LEN, BATCH_SIZE, PRE_TRAINED_MODEL_NAME)"
      ],
      "metadata": {
        "id": "yY63uWHnDmII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transf, y_train = transform_data(transf=BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME),data_loader=train_data_loader,device=device,n_hidden_layer=[1]) #номер скрытого слоя для извлечения представления, если не указан, то берется выход для CLF\n",
        "test_transf, y_test = transform_data(transf=BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME),data_loader=test_data_loader,device=device,n_hidden_layer=[1]) #номер скрытого слоя для извлечения представления, если не указан, то берется выход для CLF"
      ],
      "metadata": {
        "id": "0Wk3pS0GFIGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(max_iter=1000)\n",
        "print('Accuracy, train(cv=3): ', sum(cross_val_score(clf, img_of_txt(train_transf, var=[-1]), y_train, cv=3))/3)\n",
        "clf.fit(img_of_txt(train_transf, var=[-1]), y_train)\n",
        "print('Accuracy, test:' ,accuracy_score(y_test, clf.predict(img_of_txt(test_transf, var=[-1]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HwDTXV7Gpn4",
        "outputId": "67685ae4-10a6-4fbf-aa78-10c461514892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy, train(cv=3):  0.8295428816617879\n",
            "Accuracy, test: 0.8292682926829268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-large-uncased'\n",
        "train_data_loader, test_data_loader, tokenizer = create_new_transf(train, test, tokenizer, MAX_LEN, BATCH_SIZE, PRE_TRAINED_MODEL_NAME)"
      ],
      "metadata": {
        "id": "jdcw9sMBHt1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transf, y_train = transform_data(transf=BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME),data_loader=train_data_loader,device=device,n_hidden_layer=[1]) #номер скрытого слоя для извлечения представления, если не указан, то берется выход для CLF\n",
        "test_transf, y_test = transform_data(transf=BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME),data_loader=test_data_loader,device=device,n_hidden_layer=[1]) #номер скрытого слоя для извлечения представления, если не указан, то берется выход для CLF"
      ],
      "metadata": {
        "id": "hmhch1laHt1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(max_iter=1000)\n",
        "print('Accuracy, train(cv=3): ', sum(cross_val_score(clf, img_of_txt(train_transf, var=[-1]), y_train, cv=3))/3)\n",
        "clf.fit(img_of_txt(train_transf, var=[-1]), y_train)\n",
        "print('Accuracy, test:' ,accuracy_score(y_test, clf.predict(img_of_txt(test_transf, var=[-1]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d3cfd2a-a04a-4a13-9719-c05f4451eefa",
        "id": "muku12f1Ht1J"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy, train(cv=3):  0.8422039128849549\n",
            "Accuracy, test: 0.8245778611632271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "train_data_loader, test_data_loader, tokenizer = create_new_transf(train, test, tokenizer, MAX_LEN, BATCH_SIZE, PRE_TRAINED_MODEL_NAME)"
      ],
      "metadata": {
        "id": "9U8jXZkNJF5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transf, y_train = transform_data(transf=BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME),data_loader=train_data_loader,device=device,n_hidden_layer=[1]) #номер скрытого слоя для извлечения представления, если не указан, то берется выход для CLF\n",
        "test_transf, y_test = transform_data(transf=BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME),data_loader=test_data_loader,device=device,n_hidden_layer=[1]) #номер скрытого слоя для извлечения представления, если не указан, то берется выход для CLF"
      ],
      "metadata": {
        "id": "YbhDfITXJF5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(max_iter=1000)\n",
        "print('Accuracy, train(cv=3): ', sum(cross_val_score(clf, img_of_txt(train_transf, var=[-1]), y_train, cv=3))/3)\n",
        "clf.fit(img_of_txt(train_transf, var=[-1]), y_train)\n",
        "print('Accuracy, test:' ,accuracy_score(y_test, clf.predict(img_of_txt(test_transf, var=[-1]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af188ebe-a034-4424-84cb-a877dfec6d8d",
        "id": "X5oRBjX_JF5z"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy, train(cv=3):  0.8057438763982039\n",
            "Accuracy, test: 0.8161350844277674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\n",
        "train_data_loader, test_data_loader, tokenizer = create_new_transf(train, test, tokenizer, MAX_LEN, BATCH_SIZE, PRE_TRAINED_MODEL_NAME)"
      ],
      "metadata": {
        "id": "rRwWO79NJJtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transf, y_train = transform_data(transf=BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME),data_loader=train_data_loader,device=device,n_hidden_layer=[1]) #номер скрытого слоя для извлечения представления, если не указан, то берется выход для CLF\n",
        "test_transf, y_test = transform_data(transf=BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME),data_loader=test_data_loader,device=device,n_hidden_layer=[1]) #номер скрытого слоя для извлечения представления, если не указан, то берется выход для CLF"
      ],
      "metadata": {
        "id": "WFRxoTjkJJtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(max_iter=1000)\n",
        "print('Accuracy, train(cv=3): ', sum(cross_val_score(clf, img_of_txt(train_transf, var=[-1]), y_train, cv=3))/3)\n",
        "clf.fit(img_of_txt(train_transf, var=[-1]), y_train)\n",
        "print('Accuracy, test:' ,accuracy_score(y_test, clf.predict(img_of_txt(test_transf, var=[-1]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39029a57-85d8-4c5f-a7c9-58c05dd456d5",
        "id": "6beNrRpAJJtR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy, train(cv=3):  0.815827410378985\n",
            "Accuracy, test: 0.8030018761726079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'roberta-base'\n",
        "train_data_loader, test_data_loader, tokenizer = create_new_transf(train, test, tokenizer, MAX_LEN, BATCH_SIZE, PRE_TRAINED_MODEL_NAME)"
      ],
      "metadata": {
        "id": "IyVnMAkKKPyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transf, y_train = transform_data(transf=RobertaModel.from_pretrained(PRE_TRAINED_MODEL_NAME),data_loader=train_data_loader,device=device,n_hidden_layer=[1]) #номер скрытого слоя для извлечения представления, если не указан, то берется выход для CLF\n",
        "test_transf, y_test = transform_data(transf=RobertaModel.from_pretrained(PRE_TRAINED_MODEL_NAME),data_loader=test_data_loader,device=device,n_hidden_layer=[1]) #номер скрытого слоя для извлечения представления, если не указан, то берется выход для CLF"
      ],
      "metadata": {
        "id": "kfJsfwHaKPyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(max_iter=1000)\n",
        "print('Accuracy, train(cv=3): ', sum(cross_val_score(clf, img_of_txt(train_transf, var=[-1]), y_train, cv=3))/3)\n",
        "clf.fit(img_of_txt(train_transf, var=[-1]), y_train)\n",
        "print('Accuracy, test:' ,accuracy_score(y_test, clf.predict(img_of_txt(test_transf, var=[-1]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "378505bb-b536-4aad-f789-4dc43e02e5f6",
        "id": "YEz9m2cKKPyl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy, train(cv=3):  0.6301288777479465\n",
            "Accuracy, test: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'roberta-large'\n",
        "train_data_loader, test_data_loader, tokenizer = create_new_transf(train, test, tokenizer, MAX_LEN, BATCH_SIZE, PRE_TRAINED_MODEL_NAME)"
      ],
      "metadata": {
        "id": "KdgfavOBKP7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transf, y_train = transform_data(transf=RobertaModel.from_pretrained(PRE_TRAINED_MODEL_NAME),data_loader=train_data_loader,device=device,n_hidden_layer=[1]) #номер скрытого слоя для извлечения представления, если не указан, то берется выход для CLF\n",
        "test_transf, y_test = transform_data(transf=RobertaModel.from_pretrained(PRE_TRAINED_MODEL_NAME),data_loader=test_data_loader,device=device,n_hidden_layer=[1]) #номер скрытого слоя для извлечения представления, если не указан, то берется выход для CLF"
      ],
      "metadata": {
        "id": "6mEFkrF0KP7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(max_iter=1000)\n",
        "print('Accuracy, train(cv=3): ', sum(cross_val_score(clf, img_of_txt(train_transf, var=[-1]), y_train, cv=3))/3)\n",
        "clf.fit(img_of_txt(train_transf, var=[-1]), y_train)\n",
        "print('Accuracy, test:' ,accuracy_score(y_test, clf.predict(img_of_txt(test_transf, var=[-1]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c434800-320d-4a1c-8184-e34af75ce390",
        "id": "bzJj2TYsKP7F"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy, train(cv=3):  0.8427901068564122\n",
            "Accuracy, test: 0.850844277673546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'albert-base-v2'\n",
        "train_data_loader, test_data_loader, tokenizer = create_new_transf(train, test, tokenizer, MAX_LEN, BATCH_SIZE, PRE_TRAINED_MODEL_NAME)"
      ],
      "metadata": {
        "id": "Y7PXpnhaQM3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transf, y_train = transform_data(transf=AlbertModel.from_pretrained(PRE_TRAINED_MODEL_NAME),data_loader=train_data_loader,device=device,n_hidden_layer=[1]) #номер скрытого слоя для извлечения представления, если не указан, то берется выход для CLF\n",
        "test_transf, y_test = transform_data(transf=AlbertModel.from_pretrained(PRE_TRAINED_MODEL_NAME),data_loader=test_data_loader,device=device,n_hidden_layer=[1]) #номер скрытого слоя для извлечения представления, если не указан, то берется выход для CLF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20c16cd6-9d7a-4409-eb55-fa3e9a0692d2",
        "id": "3oCfyWTvQM3y"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.dense.weight', 'predictions.decoder.bias', 'predictions.dense.bias', 'predictions.LayerNorm.bias', 'predictions.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.weight']\n",
            "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(max_iter=1000)\n",
        "print('Accuracy, train(cv=3): ', sum(cross_val_score(clf, img_of_txt(train_transf, var=[-1]), y_train, cv=3))/3)\n",
        "clf.fit(img_of_txt(train_transf, var=[-1]), y_train)\n",
        "print('Accuracy, test:' ,accuracy_score(y_test, clf.predict(img_of_txt(test_transf, var=[-1]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3db175e2-5843-4726-969d-4b648bf4f495",
        "id": "7a6dJVv5QM3y"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy, train(cv=3):  0.8337627856577353\n",
            "Accuracy, test: 0.8170731707317073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Код для подсчета accuracy для различных ML моделей (4 эксперимент)"
      ],
      "metadata": {
        "id": "ykxTfqnCZL0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'roberta-large'\n",
        "train_data_loader, test_data_loader, tokenizer = create_new_transf(train, test, tokenizer, MAX_LEN, BATCH_SIZE, PRE_TRAINED_MODEL_NAME)"
      ],
      "metadata": {
        "id": "cFvjD8mvZR4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transf, y_train = transform_data(transf=RobertaModel.from_pretrained(PRE_TRAINED_MODEL_NAME),data_loader=train_data_loader,device=device,n_hidden_layer=[1]) #номер скрытого слоя для извлечения представления, если не указан, то берется выход для CLF\n",
        "test_transf, y_test = transform_data(transf=RobertaModel.from_pretrained(PRE_TRAINED_MODEL_NAME),data_loader=test_data_loader,device=device,n_hidden_layer=[1]) #номер скрытого слоя для извлечения представления, если не указан, то берется выход для CLF"
      ],
      "metadata": {
        "id": "nykwz0WbZR4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(max_iter=1000)\n",
        "print('Accuracy, train(cv=3): ', sum(cross_val_score(clf, img_of_txt(train_transf, var=[-1]), y_train, cv=3))/3)\n",
        "clf.fit(img_of_txt(train_transf, var=[-1]), y_train)\n",
        "print('Accuracy, test:' ,accuracy_score(y_test, clf.predict(img_of_txt(test_transf, var=[-1]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec6cdbc9-9f5d-4b1b-a4cb-0f813546beb8",
        "id": "cBMClcgnZR4v"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy, train(cv=3):  0.8427901068564122\n",
            "Accuracy, test: 0.850844277673546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = SVC()\n",
        "print('Accuracy, train(cv=3): ', sum(cross_val_score(clf, img_of_txt(train_transf, var=[-1]), y_train, cv=3))/3)\n",
        "clf.fit(img_of_txt(train_transf, var=[-1]), y_train)\n",
        "print('Accuracy, test:' ,accuracy_score(y_test, clf.predict(img_of_txt(test_transf, var=[-1]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THCeaVGqaZWa",
        "outputId": "5fd9f3b4-51d9-4ea9-da39-bb998756e37e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy, train(cv=3):  0.7858147655083946\n",
            "Accuracy, test: 0.8020637898686679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = KNeighborsClassifier()\n",
        "print('Accuracy, train(cv=3): ', sum(cross_val_score(clf, img_of_txt(train_transf, var=[-1]), y_train, cv=3))/3)\n",
        "clf.fit(img_of_txt(train_transf, var=[-1]), y_train)\n",
        "print('Accuracy, test:' ,accuracy_score(y_test, clf.predict(img_of_txt(test_transf, var=[-1]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZEhlka3a0Wi",
        "outputId": "6fb70a44-a521-4e28-cf67-749d1c3db38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy, train(cv=3):  0.6957800877588319\n",
            "Accuracy, test: 0.6894934333958724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = DecisionTreeClassifier()\n",
        "print('Accuracy, train(cv=3): ', sum(cross_val_score(clf, img_of_txt(train_transf, var=[-1]), y_train, cv=3))/3)\n",
        "clf.fit(img_of_txt(train_transf, var=[-1]), y_train)\n",
        "print('Accuracy, test:' ,accuracy_score(y_test, clf.predict(img_of_txt(test_transf, var=[-1]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syr3TbHlbKgJ",
        "outputId": "39815d82-45a8-4097-abf2-179cb25645c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy, train(cv=3):  0.6388044578280868\n",
            "Accuracy, test: 0.6407129455909943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = GradientBoostingClassifier()\n",
        "print('Accuracy, train(cv=3): ', sum(cross_val_score(clf, img_of_txt(train_transf, var=[-1]), y_train, cv=3))/3)\n",
        "clf.fit(img_of_txt(train_transf, var=[-1]), y_train)\n",
        "print('Accuracy, test:' ,accuracy_score(y_test, clf.predict(img_of_txt(test_transf, var=[-1]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2zeD23sbY_8",
        "outputId": "95070984-ff37-41fe-d59d-bb9c04450e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy, train(cv=3):  0.7969517501223179\n",
            "Accuracy, test: 0.8039399624765479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = AdaBoostClassifier()\n",
        "print('Accuracy, train(cv=3): ', sum(cross_val_score(clf, img_of_txt(train_transf, var=[-1]), y_train, cv=3))/3)\n",
        "clf.fit(img_of_txt(train_transf, var=[-1]), y_train)\n",
        "print('Accuracy, test:' ,accuracy_score(y_test, clf.predict(img_of_txt(test_transf, var=[-1]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxxo7pnNbzpO",
        "outputId": "5bab98e0-fe6d-4d0c-fcc7-17c04641a49c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy, train(cv=3):  0.7695189111559321\n",
            "Accuracy, test: 0.7589118198874296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier()\n",
        "print('Accuracy, train(cv=3): ', sum(cross_val_score(clf, img_of_txt(train_transf, var=[-1]), y_train, cv=3))/3)\n",
        "clf.fit(img_of_txt(train_transf, var=[-1]), y_train)\n",
        "print('Accuracy, test:' ,accuracy_score(y_test, clf.predict(img_of_txt(test_transf, var=[-1]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOsRQuZ6b-bp",
        "outputId": "d5d93e12-9cdf-4cca-ea59-1b242e4faf75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy, train(cv=3):  0.7726846224488669\n",
            "Accuracy, test: 0.774859287054409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = XGBClassifier()\n",
        "print('Accuracy, train(cv=3): ', sum(cross_val_score(clf, img_of_txt(train_transf, var=[-1]), y_train, cv=3))/3)\n",
        "clf.fit(img_of_txt(train_transf, var=[-1]), y_train)\n",
        "print('Accuracy, test:' ,accuracy_score(y_test, clf.predict(img_of_txt(test_transf, var=[-1]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJPAemAbcZsC",
        "outputId": "f5fe523d-6180-4aa8-e76f-a49e07837d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy, train(cv=3):  0.800117296510837\n",
            "Accuracy, test: 0.8095684803001876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = CatBoostClassifier(logging_level='Silent')\n",
        "print('Accuracy, train(cv=3): ', sum(cross_val_score(clf, img_of_txt(train_transf, var=[-1]), y_train, cv=3))/3)\n",
        "clf.fit(img_of_txt(train_transf, var=[-1]), y_train)\n",
        "print('Accuracy, test:' ,accuracy_score(y_test, clf.predict(img_of_txt(test_transf, var=[-1]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEz96qvBfsSh",
        "outputId": "bdd8ab78-26f3-47c3-ba26-abcdb5608f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy, train(cv=3):  0.8207501369943433\n",
            "Accuracy, test: 0.8255159474671669\n"
          ]
        }
      ]
    }
  ]
}